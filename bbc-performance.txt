###################################################################
               Multinomial default values, try 1
###################################################################

(b): confusion matrix
[[ 97   0   4   0   0]
 [  0  76   1   0   3]
 [  2   1  80   0   1]
 [  0   0   0 111   0]
 [  0   1   0   0  68]]

(c): classification report
               precision    recall  f1-score   support

     business       0.98      0.96      0.97       101
entertainment       0.97      0.95      0.96        80
     politics       0.94      0.95      0.95        84
        sport       1.00      1.00      1.00       111
         tech       0.94      0.99      0.96        69

     accuracy                           0.97       445
    macro avg       0.97      0.97      0.97       445
 weighted avg       0.97      0.97      0.97       445


(d): accuracy, macro f1, weighted f1
accuracy: 0.9707865168539326
macro f1: 0.9686619771356144
weighted f1: 0.9708131326398929

(e): prior probabilities
Business: 22.70% 
Entertainment: 17.98% 
Politics: 18.88% 
Sport: 24.94% 
Tech: 15.51% 

(f): size of vocabulary 
Vocabulary size: 29421

(g): number of word tokens in each classBusiness: 164663 
Entertainment: 124893 
Politics: 185208 
Sport: 162953 
Tech: 198640 

(h): number of word tokens in entire corpus
Number of word tokens in corpus: 836357

(i): number and percentage of words with frequency 0 per class
Business: 17538 59.61%
Entertainment: 17746 60.32%
Politics: 18201 61.86%
Sport: 18850 64.07%
Tech: 17323 58.88%

(j): number and percentage of words with frequency of 1 in the entire corpus
Number: 10005, Percentage: 34.01%

(k): log probability of 2 favourite words (people, american)
People: 6.013657765929906
American: 8.168750693271678




###################################################################
               Multinomial default values, try 2
###################################################################

(b): confusion matrix
[[ 97   0   4   0   0]
 [  0  76   1   0   3]
 [  2   1  80   0   1]
 [  0   0   0 111   0]
 [  0   1   0   0  68]]

(c): classification report
               precision    recall  f1-score   support

     business       0.98      0.96      0.97       101
entertainment       0.97      0.95      0.96        80
     politics       0.94      0.95      0.95        84
        sport       1.00      1.00      1.00       111
         tech       0.94      0.99      0.96        69

     accuracy                           0.97       445
    macro avg       0.97      0.97      0.97       445
 weighted avg       0.97      0.97      0.97       445


(d): accuracy, macro f1, weighted f1
accuracy: 0.9707865168539326
macro f1: 0.9686619771356144
weighted f1: 0.9708131326398929

(e): prior probabilities
Business: 22.70% 
Entertainment: 17.98% 
Politics: 18.88% 
Sport: 24.94% 
Tech: 15.51% 

(f): size of vocabulary 
Vocabulary size: 29421

(g): number of word tokens in each classBusiness: 164663 
Entertainment: 124893 
Politics: 185208 
Sport: 162953 
Tech: 198640 

(h): number of word tokens in entire corpus
Number of word tokens in corpus: 836357

(i): number and percentage of words with frequency 0 per class
Business: 17538 59.61%
Entertainment: 17746 60.32%
Politics: 18201 61.86%
Sport: 18850 64.07%
Tech: 17323 58.88%

(j): number and percentage of words with frequency of 1 in the entire corpus
Number: 10005, Percentage: 34.01%

(k): log probability of 2 favourite words (people, american)
People: 6.013657765929906
American: 8.168750693271678




###################################################################
     Multinomial default values, try 3 with smoothing = 0.001
###################################################################

(b): confusion matrix
[[ 96   1   4   0   0]
 [  1  76   2   0   1]
 [  3   0  79   0   2]
 [  0   0   0 111   0]
 [  0   1   0   0  68]]

(c): classification report
               precision    recall  f1-score   support

     business       0.96      0.95      0.96       101
entertainment       0.97      0.95      0.96        80
     politics       0.93      0.94      0.93        84
        sport       1.00      1.00      1.00       111
         tech       0.96      0.99      0.97        69

     accuracy                           0.97       445
    macro avg       0.96      0.97      0.96       445
 weighted avg       0.97      0.97      0.97       445


(d): accuracy, macro f1, weighted f1
accuracy: 0.9662921348314607
macro f1: 0.9647178022169666
weighted f1: 0.966293827110166

(e): prior probabilities
Business: 22.70% 
Entertainment: 17.98% 
Politics: 18.88% 
Sport: 24.94% 
Tech: 15.51% 

(f): size of vocabulary 
Vocabulary size: 29421

(g): number of word tokens in each classBusiness: 164663 
Entertainment: 124893 
Politics: 185208 
Sport: 162953 
Tech: 198640 

(h): number of word tokens in entire corpus
Number of word tokens in corpus: 836357

(i): number and percentage of words with frequency 0 per class
Business: 17538 59.61%
Entertainment: 17746 60.32%
Politics: 18201 61.86%
Sport: 18850 64.07%
Tech: 17323 58.88%

(j): number and percentage of words with frequency of 1 in the entire corpus
Number: 10005, Percentage: 34.01%

(k): log probability of 2 favourite words (people, american)
People: 6.013657765929906
American: 8.168750693271678




###################################################################
      Multinomial default values, try 4 with smoothing = 0.9
###################################################################

(b): confusion matrix
[[ 97   0   4   0   0]
 [  0  76   1   0   3]
 [  2   1  80   0   1]
 [  0   0   0 111   0]
 [  0   1   0   0  68]]

(c): classification report
               precision    recall  f1-score   support

     business       0.98      0.96      0.97       101
entertainment       0.97      0.95      0.96        80
     politics       0.94      0.95      0.95        84
        sport       1.00      1.00      1.00       111
         tech       0.94      0.99      0.96        69

     accuracy                           0.97       445
    macro avg       0.97      0.97      0.97       445
 weighted avg       0.97      0.97      0.97       445


(d): accuracy, macro f1, weighted f1
accuracy: 0.9707865168539326
macro f1: 0.9686619771356144
weighted f1: 0.9708131326398929

(e): prior probabilities
Business: 22.70% 
Entertainment: 17.98% 
Politics: 18.88% 
Sport: 24.94% 
Tech: 15.51% 

(f): size of vocabulary 
Vocabulary size: 29421

(g): number of word tokens in each classBusiness: 164663 
Entertainment: 124893 
Politics: 185208 
Sport: 162953 
Tech: 198640 

(h): number of word tokens in entire corpus
Number of word tokens in corpus: 836357

(i): number and percentage of words with frequency 0 per class
Business: 17538 59.61%
Entertainment: 17746 60.32%
Politics: 18201 61.86%
Sport: 18850 64.07%
Tech: 17323 58.88%

(j): number and percentage of words with frequency of 1 in the entire corpus
Number: 10005, Percentage: 34.01%

(k): log probability of 2 favourite words (people, american)
People: 6.013657765929906
American: 8.168750693271678

