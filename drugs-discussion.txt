8) Certain models give us the same results, and others do not. The naive bayes, decision tree and perceptron classifiers
   all give the same results all the time. This is because they are all simple mathematical equations. We are giving the
   same numbers to the probability, entropy and activation functions. As such, we always get the same results.

   The perceptron converges in a single iteration, hence further iterations have not improved results.
   However, because the MLP does not converge on the first iteration hence the performance changes on subsequent iterations.
